ğŸ§® ComunicaÃ§Ã£o Ponto a Ponto em MPI â€” Ping-Pong
  Este projeto implementa uma simulaÃ§Ã£o de comunicaÃ§Ã£o ponto a ponto utilizando a biblioteca MPI (Message Passing Interface) com o mÃ³dulo mpi4py em Python. O objetivo Ã© medir o tempo de transmissÃ£o e recepÃ§Ã£o de mensagens entre dois processos, o Processo 0 e o Processo 1, no clÃ¡ssico experimento conhecido como â€œPing-Pongâ€. A partir disso, calcula-se tambÃ©m a taxa de transferÃªncia em megabytes por segundo (MB/s) para diferentes tamanhos de mensagem.
  O cÃ³digo foi desenvolvido de forma didÃ¡tica, com comentÃ¡rios explicativos em cada etapa, e realiza a exportaÃ§Ã£o dos resultados em um arquivo CSV, permitindo anÃ¡lise posterior em planilhas ou ferramentas de visualizaÃ§Ã£o.
âš™ï¸ Tecnologias utilizadas
  O programa foi desenvolvido em Python 3 e faz uso das bibliotecas mpi4py (para comunicaÃ§Ã£o entre processos MPI), NumPy (para geraÃ§Ã£o eficiente de arrays de nÃºmeros aleatÃ³rios do tipo double) e o mÃ³dulo nativo csv (para exportaÃ§Ã£o dos resultados).
ğŸ“¦ InstalaÃ§Ã£o
  Para executar o programa, Ã© necessÃ¡rio ter o MPI instalado no sistema, como o OpenMPI, e a biblioteca mpi4py configurada no ambiente Python. Em sistemas baseados em macOS, pode-se instalar o OpenMPI utilizando o Homebrew. JÃ¡ em sistemas Linux, Ã© possÃ­vel instalar via apt-get. ApÃ³s isso, basta instalar as dependÃªncias Python mpi4py e numpy usando o pip.
â–¶ï¸ ExecuÃ§Ã£o
  O programa deve ser executado com dois processos, simulando o envio e retorno da mensagem. Isso Ã© feito a partir do terminal, dentro da pasta onde o cÃ³digo estÃ¡ localizado. Ã‰ importante ressaltar que o parÃ¢metro â€œ-np 2â€ Ã© obrigatÃ³rio, pois o cÃ³digo foi projetado especificamente para dois processos: um responsÃ¡vel pelo envio e outro pela recepÃ§Ã£o e devoluÃ§Ã£o dos dados.
ğŸ“Š Funcionamento
  O funcionamento segue as seguintes etapas. Primeiro, o programa gera um array de tamanho n = 2 elevado a exp, variando exponencialmente de 1 atÃ© 2Â¹â¹ doubles. Em seguida, o Processo 0 envia o array para o Processo 1 utilizando o mÃ©todo Send. O Processo 1 recebe os dados com Recv, e entÃ£o devolve o mesmo array de volta ao Processo 0, completando assim o ciclo de envio e recepÃ§Ã£o.
  O Processo 0 mede o tempo total da operaÃ§Ã£o, somando o tempo de ida e volta, por meio do mÃ©todo MPI.Wtime(). A partir desses valores, o cÃ³digo calcula o tempo total, o volume total de dados transferidos (considerando que cada double ocupa 8 bytes e que hÃ¡ envio e retorno) e a taxa de transferÃªncia em megabytes por segundo. Por fim, todos os resultados sÃ£o armazenados em uma lista de dicionÃ¡rios e exportados automaticamente para um arquivo CSV denominado â€œResultados.csvâ€.
ğŸ“ Estrutura do projeto
  O projeto Ã© composto basicamente por trÃªs arquivos: o script principal (mpi.py), o arquivo de resultados (Resultados.csv), gerado automaticamente apÃ³s a execuÃ§Ã£o, e o arquivo de documentaÃ§Ã£o (README.md).
ğŸ§¾ Exemplo de saÃ­da no terminal
  Durante a execuÃ§Ã£o, o terminal exibirÃ¡ mensagens informativas sobre o envio e recebimento dos dados, seguidas dos resultados de tempo e taxa de transferÃªncia para cada tamanho de mensagem. Ã‰ importante destacar que as mensagens podem aparecer fora de ordem no terminal, devido Ã  execuÃ§Ã£o paralela dos processos MPI. Essa desorganizaÃ§Ã£o Ã© natural e nÃ£o afeta a precisÃ£o das mediÃ§Ãµes.
ğŸ“‘ SaÃ­da em arquivo CSV
  O arquivo gerado â€œResultados.csvâ€ conterÃ¡ uma tabela com as colunas: operaÃ§Ã£o, n (doubles), tempo (s) e taxa (MB/s). Cada linha representa uma mediÃ§Ã£o correspondente a um tamanho de array diferente, com a operaÃ§Ã£o â€œSend/Recvâ€ indicando o tipo de comunicaÃ§Ã£o realizada.
ğŸ§  Conceito envolvido
  O experimento segue o padrÃ£o clÃ¡ssico de benchmark â€œPing-Pongâ€, amplamente utilizado para avaliar o desempenho de sistemas distribuÃ­dos. Esse modelo mede tanto a latÃªncia (o tempo necessÃ¡rio para enviar e receber uma mensagem) quanto a largura de banda (a taxa de transferÃªncia de dados). Tais mÃ©tricas sÃ£o essenciais para compreender o comportamento e a eficiÃªncia de clusters, redes interconectadas e aplicaÃ§Ãµes paralelas que dependem de comunicaÃ§Ã£o entre processos.
ğŸ’¬ ObservaÃ§Ãµes
  O programa nÃ£o impÃµe sincronizaÃ§Ã£o adicional para forÃ§ar a ordem das mensagens no terminal, pois isso alteraria os resultados dos tempos medidos. Apenas o Processo 0 Ã© responsÃ¡vel por calcular os tempos e gravar as informaÃ§Ãµes no arquivo CSV. O cÃ³digo foi desenvolvido com fins acadÃªmicos e didÃ¡ticos, servindo como um exemplo prÃ¡tico de comunicaÃ§Ã£o ponto a ponto utilizando MPI em Python.
ğŸ‘¨â€ğŸ’» Autor
Projeto desenvolvido por Leonardo Farias, como parte das atividades da disciplina de Sistemas DistribuÃ­dos.
